{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 1"
      ],
      "metadata": {
        "id": "2iorcqwITgqm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## libraries imports"
      ],
      "metadata": {
        "id": "h_ll1gH0TtD1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.9.0+cu102 torchvision==0.10.0+cu102 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZ-7PqBuQyL0",
        "outputId": "6c36d230-c54a-465e-f804-a90cfb930ade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.9.0+cu102\n",
            "  Downloading https://download.pytorch.org/whl/cu102/torch-1.9.0%2Bcu102-cp37-cp37m-linux_x86_64.whl (831.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 831.4 MB 2.9 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.10.0+cu102\n",
            "  Downloading https://download.pytorch.org/whl/cu102/torchvision-0.10.0%2Bcu102-cp37-cp37m-linux_x86_64.whl (22.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.1 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting torchaudio==0.9.0\n",
            "  Downloading torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 23.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0+cu102) (4.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu102) (1.21.6)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu102) (7.1.2)\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1+cu113\n",
            "    Uninstalling torch-1.12.1+cu113:\n",
            "      Successfully uninstalled torch-1.12.1+cu113\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.13.1+cu113\n",
            "    Uninstalling torchvision-0.13.1+cu113:\n",
            "      Successfully uninstalled torchvision-0.13.1+cu113\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 0.12.1+cu113\n",
            "    Uninstalling torchaudio-0.12.1+cu113:\n",
            "      Successfully uninstalled torchaudio-0.12.1+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.9.0+cu102 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.9.0+cu102 torchaudio-0.9.0 torchvision-0.10.0+cu102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "wqKJyW4nWHo6"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mnist dataset import"
      ],
      "metadata": {
        "id": "gA0hFJXaT3cT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist"
      ],
      "metadata": {
        "id": "DJgrGpY-XCYM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "mnist = fetch_openml ('mnist_784', cache = False )"
      ],
      "metadata": {
        "id": "wWP5XHF_ZjbN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = mnist.data.astype('float32')\n",
        "y = mnist.target.astype('int64')"
      ],
      "metadata": {
        "id": "luGQz6mTZve6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset split into train,validation and test set"
      ],
      "metadata": {
        "id": "k_68HIAwT7bv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_split(X,y,train,validation,test):\n",
        "  X_train = X[:int(len(X)*(round(train/100,2)))]\n",
        "  y_train = y[:len(X_train)]\n",
        "  X_validation = X[len(X_train):int(len(X)*(round((train+validation)/100,2)))]\n",
        "  y_validation = y[len(X_train):len(X_validation)+len(X_train)]\n",
        "  X_test = X[int(len(X)*(round((train+validation)/100,2))):]\n",
        "  y_test = y[len(X_train) + len(X_validation):]\n",
        "\n",
        "  return X_train.reset_index(drop=True),y_train.reset_index(drop=True),X_test.reset_index(drop=True),y_test.reset_index(drop=True),X_validation.reset_index(drop=True),y_validation.reset_index(drop=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "pCP8GY1eaJAa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " X_train,y_train,X_test,y_test,X_validation,y_validation = data_split(X,y,70,15,15)"
      ],
      "metadata": {
        "id": "pMHjXLBkaUXH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset distribution check"
      ],
      "metadata": {
        "id": "0O5gz3V4UBme"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we check if the distribution is 70-15-15  "
      ],
      "metadata": {
        "id": "IQaTDhP3bn64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def distrib_check(y_train,y_test,y_val):\n",
        "  y_df = y_train.to_frame()\n",
        "  result = y_df.groupby(['class'])['class'].count() \n",
        "  \n",
        "  y_df = y_test.to_frame()\n",
        "  result2= y_df.groupby(['class'])['class'].count()\n",
        "\n",
        "  y_df = y_val.to_frame()\n",
        "  result3 = y_df.groupby(['class'])['class'].count()\n",
        "  \n",
        "  for i in range(0,10):\n",
        "    dist_train = result[i]/(result[i]+result2[i]+ result3[i])\n",
        "    dist_test = result2[i]/(result[i]+result2[i]+ result3[i])\n",
        "    dist_val = result3[i]/(result[i]+result2[i]+ result3[i])\n",
        "    print(f'Ratios : {i} , train : {round(dist_train*100,2)} % , test : {round(dist_test*100,2)} % , validation : {round(dist_val*100,2)} %'  )\n",
        "distrib_check(y_train,y_test,y_validation)\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbdJJ6WYbmp6",
        "outputId": "4f118a9c-5144-4a88-be39-6eadcdfcbe6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ratios : 0 , train : 69.9 % , test : 14.86 % , validation : 15.24 %\n",
            "Ratios : 1 , train : 70.71 % , test : 15.09 % , validation : 14.19 %\n",
            "Ratios : 2 , train : 69.63 % , test : 15.51 % , validation : 14.86 %\n",
            "Ratios : 3 , train : 69.82 % , test : 14.82 % , validation : 15.36 %\n",
            "Ratios : 4 , train : 69.94 % , test : 15.14 % , validation : 14.92 %\n",
            "Ratios : 5 , train : 69.79 % , test : 14.83 % , validation : 15.38 %\n",
            "Ratios : 6 , train : 70.61 % , test : 14.73 % , validation : 14.66 %\n",
            "Ratios : 7 , train : 69.6 % , test : 14.85 % , validation : 15.55 %\n",
            "Ratios : 8 , train : 69.61 % , test : 14.95 % , validation : 15.44 %\n",
            "Ratios : 9 , train : 70.29 % , test : 15.21 % , validation : 14.5 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So data is distributed properly throw all datasets"
      ],
      "metadata": {
        "id": "E_FMPKGShXlt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transform dataframe to tensors"
      ],
      "metadata": {
        "id": "7R40GB7oUJB_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor = torch.tensor(X_train.to_numpy())\n",
        "X_test_tensor = torch.tensor(X_test.to_numpy())\n",
        "X_validation_tensor = torch.tensor(X_validation.to_numpy())\n",
        "\n",
        "y_train_torch = torch.tensor(y_train.to_numpy())\n",
        "y_test_torch = torch.tensor(y_test.to_numpy())\n",
        "y_validation_torch = torch.tensor(y_validation.to_numpy())"
      ],
      "metadata": {
        "id": "mPz1fFJmbKc8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor = X_train_tensor/255.0\n",
        "X_test_tensor = X_test_tensor/255.0\n",
        "X_validation_tensor = X_validation_tensor/255.0"
      ],
      "metadata": {
        "id": "MjYPvrcefiu_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create dataset with only 2 and 3 digits"
      ],
      "metadata": {
        "id": "Mx9BRnSVUPXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_torch_2 = X_train_tensor[torch.where(y_train_torch == 2)[0]] \n",
        "x_train_torch_3 = X_train_tensor[torch.where(y_train_torch == 3)[0]] \n",
        "\n",
        "x_test_torch_2 = X_test_tensor[torch.where(y_test_torch == 2)[0]] \n",
        "x_test_torch_3 = X_test_tensor[torch.where(y_test_torch == 3)[0]] \n",
        "\n",
        "\n",
        "x_val_torch_2 = X_validation_tensor[torch.where(y_validation_torch == 2)[0]] \n",
        "x_val_torch_3 = X_validation_tensor[torch.where(y_validation_torch == 3)[0]] "
      ],
      "metadata": {
        "id": "0TZycTfQn42F"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_torch_23 = torch.cat((x_train_torch_2,x_train_torch_3),0)\n",
        "x_test_torch_23 = torch.cat((x_test_torch_2,x_test_torch_3),0)\n",
        "x_validation_torch_23 = torch.cat((x_val_torch_2,x_val_torch_3),0)"
      ],
      "metadata": {
        "id": "IX6aVMepqg-i"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_torch_2 = y_train_torch[torch.where(y_train_torch == 2 )]\n",
        "y_train_torch_3 = y_train_torch[torch.where(y_train_torch == 3 )]\n",
        "\n",
        "y_test_torch_2 = y_test_torch[torch.where(y_test_torch == 2 )]\n",
        "y_test_torch_3 = y_test_torch[torch.where(y_test_torch == 3 )]\n",
        "\n",
        "y_val_torch_2 = y_validation_torch[torch.where(y_validation_torch == 2 )]\n",
        "y_val_torch_3 = y_validation_torch[torch.where(y_validation_torch == 3 )]\n",
        "\n"
      ],
      "metadata": {
        "id": "qKWZxURxq1xN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_torch_23 = torch.cat((y_train_torch_2,y_train_torch_3),0)\n",
        "y_test_torch_23 = torch.cat((y_test_torch_2,y_test_torch_3),0)\n",
        "y_val_torch_23 = torch.cat((y_val_torch_2,y_val_torch_3),0)"
      ],
      "metadata": {
        "id": "iUMn0vwvrJAa"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_val_torch_23.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qStfNyP4vFUG",
        "outputId": "fe6705eb-4cfb-446e-c3c8-7a3880c3dff0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2136])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 2: **KNN** model "
      ],
      "metadata": {
        "id": "xCH_CM9x2KOf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## a) Here I made a KNN function. By default it will use Euclidean distance in order to compute distance between points "
      ],
      "metadata": {
        "id": "Rkj5Ab8Qh2pS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def KNN_train(X_train,y_train,X_test,k,distance='Euclidean'):\n",
        "  device = torch.device('cuda:0')                               # Set the device in order to use the GPU                                       \n",
        "  d = torch.tensor                                              # Set empty tensor for distance       \n",
        "  if distance == 'Euclidean' :                                  # Conditions over distance that we will choose \n",
        "    d = EuclideanDistance(X_test,X_train)\n",
        "  elif distance == 'Manhattan' : \n",
        "    d = MannhattanDistance(X_test,X_train)\n",
        "  else :\n",
        "    d = Minkowsky(X_test,X_train)\n",
        "\n",
        "  dist, idx = d.topk(k=k, largest=False)                        # Index of top K distances \n",
        "  \n",
        "  pred = KNN_prediction(dist,idx,y_train)                       # Function that returns predictions for each X_test\n",
        "  return pred                                                   # Return prediction\n",
        "  \n",
        "def KNN_prediction(dist,idx,y_train):                           # Function that returns predictions based on index of the k-nearest distances\n",
        "  predict_top_k = idx.apply_(lambda x : y_train[x])             # Retrieve labels of y_train by using indexes\n",
        "  predictions = torch.mode(predict_top_k, dim = 1)[0]           \n",
        "  return predictions \n",
        "\n",
        "def EuclideanDistance(X_test,X_train):                          # Euclidean Distance\n",
        "  d = torch.cdist(X_test,X_train,p=2)\n",
        "  return d\n",
        "\n",
        "def MannhattanDistance(X_test,X_train):                         # MannhattanDistance\n",
        "  d = torch.cdist(X_test,X_train,p=1)\n",
        "  return d\n",
        "  \n",
        "def Minkowsky(X_test,X_train):\n",
        "  d = torch.cdist(X_test,X_train,p=3)\n",
        "  return d"
      ],
      "metadata": {
        "id": "KkE_JRaxgzI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we apply our KNN model to train the train set with k = 5 and we found an accuracy of 99.6% for the train set. But we can't be sufficient by this result. We have to test our algorithm to the validation set and see if the model doesn't overfit the train set."
      ],
      "metadata": {
        "id": "2brXC1HhkOdj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred =KNN_train(x_train_torch_23,y_train_torch_23,x_train_torch_23,5)"
      ],
      "metadata": {
        "id": "hLty05edu2kI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc = torch.sum(pred == y_train_torch_23)\n",
        "print(\"Train accuracy on 2 and 3 digit\" , round(float(train_acc)/ pred.size()[0] *100,4),'%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsY3BIlhu2rK",
        "outputId": "8b8ea6de-32e6-4178-b583-d396c5f51ed4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy on 2 and 3 digit 99.5839 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We apply KNN on validation set. with k = 5. We see an accuracy of 99.5%. So the model is pretty accurate. We can trust our knn algorithm with those parameters. "
      ],
      "metadata": {
        "id": "0yDYWdgKWY5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred =KNN_train(x_train_torch_23,y_train_torch_23,x_validation_torch_23,5)"
      ],
      "metadata": {
        "id": "Y1QqMTsSu2yO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eeeaa720-3949-453b-b901-74cc69f9542a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_acc = torch.sum(pred == y_val_torch_23)\n",
        "print(\"Validation accuracy on 2 and 3 digit \" , round(float(val_acc)/ pred.size()[0] *100,4),'%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THFf1UQr0K8F",
        "outputId": "a00f40ec-d0db-4a49-a164-8bd2ed71cdb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy on 2 and 3 digit  99.5318 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally let's perform knn on our test set. We can see that the accuracy is equal to 99.6 %. We can assume that our model generalize well the situation. "
      ],
      "metadata": {
        "id": "Koze-bD2Wp7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred =KNN_train(x_train_torch_23,y_train_torch_23,x_test_torch_23,5)"
      ],
      "metadata": {
        "id": "jF0dV8111-JI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc = torch.sum(pred == y_test_torch_23)\n",
        "print(\"Validation accuracy on 2 and 3 digit \" , round(float(test_acc)/ pred.size()[0] *100,4),'%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPJ4EFQT1-Qo",
        "outputId": "9b1ee8ba-95ba-4235-ef1d-d7415e90832c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy on 2 and 3 digit  99.6265 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## b) Hyperparameters we can tune are the number of k neighboors and the distance calculation. \n",
        "In other term we can thune our model to get the best k by testing mutliple k values.\n",
        "And we can test different type of distance computation. We can test the manhattan distance or even the jackard distance.  \n"
      ],
      "metadata": {
        "id": "C4tjXCec2QGJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## c) First options for K : Let's try other k for the KNN "
      ],
      "metadata": {
        "id": "KnMo6kEY2QJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for k in range(1,20):\n",
        "  pred =KNN_train(x_train_torch_23,y_train_torch_23,x_validation_torch_23,k)\n",
        "  val_acc = torch.sum(pred == y_val_torch_23)\n",
        "  print(f\"k = {k} Validation accuracy on 2 and 3 digit \" , round(float(val_acc)/ pred.size()[0] *100,4),'%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8YyXQ6fZY8p",
        "outputId": "64b0d18e-367b-421f-8e07-899777b2b2c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k = 1 Validation accuracy on 2 and 3 digit  99.3914 %\n",
            "k = 2 Validation accuracy on 2 and 3 digit  99.4382 %\n",
            "k = 3 Validation accuracy on 2 and 3 digit  99.485 %\n",
            "k = 4 Validation accuracy on 2 and 3 digit  99.5318 %\n",
            "k = 5 Validation accuracy on 2 and 3 digit  99.5318 %\n",
            "k = 6 Validation accuracy on 2 and 3 digit  99.5787 %\n",
            "k = 7 Validation accuracy on 2 and 3 digit  99.6723 %\n",
            "k = 8 Validation accuracy on 2 and 3 digit  99.6723 %\n",
            "k = 9 Validation accuracy on 2 and 3 digit  99.6723 %\n",
            "k = 10 Validation accuracy on 2 and 3 digit  99.6723 %\n",
            "k = 11 Validation accuracy on 2 and 3 digit  99.7191 %\n",
            "k = 12 Validation accuracy on 2 and 3 digit  99.7659 %\n",
            "k = 13 Validation accuracy on 2 and 3 digit  99.7191 %\n",
            "k = 14 Validation accuracy on 2 and 3 digit  99.7191 %\n",
            "k = 15 Validation accuracy on 2 and 3 digit  99.7191 %\n",
            "k = 16 Validation accuracy on 2 and 3 digit  99.7191 %\n",
            "k = 17 Validation accuracy on 2 and 3 digit  99.6255 %\n",
            "k = 18 Validation accuracy on 2 and 3 digit  99.6255 %\n",
            "k = 19 Validation accuracy on 2 and 3 digit  99.5787 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we can find that k = 12 is the optimum for the validation test. \n",
        "After k=12 the performance of the model decreases. "
      ],
      "metadata": {
        "id": "xsNhn6QIaB75"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try k=12 on the test set. We found a good accuracy but lower than the accuracy for k = 5"
      ],
      "metadata": {
        "id": "T-GaBZAia2EY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred =KNN_train(x_train_torch_23,y_train_torch_23,x_test_torch_23,12)\n",
        "test_acc = torch.sum(pred == y_test_torch_23)\n",
        "print(\"Validation accuracy on 2 and 3 digit \" , round(float(test_acc)/ pred.size()[0] *100,4),'%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7R9XGAbax2B",
        "outputId": "8943bea1-dfea-48ae-8dcf-95d4b2a067af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy on 2 and 3 digit  99.5798 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try k=6. We found an accuracy of 99.72% for the test set. "
      ],
      "metadata": {
        "id": "akKJ2shfbD7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred =KNN_train(x_train_torch_23,y_train_torch_23,x_test_torch_23,6)\n",
        "test_acc = torch.sum(pred == y_test_torch_23)\n",
        "print(\"Validation accuracy on 2 and 3 digit \" , round(float(test_acc)/ pred.size()[0] *100,4),'%')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHLcXvtdZY-x",
        "outputId": "8c37f8c7-c9b4-4a47-b398-6f120cfb8ef5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy on 2 and 3 digit  99.7199 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Second option let's try an other distance computation for knn. I already implemented the distance inside the knn algorithm. We can now choose the distance we want to compute.\n",
        "\n",
        "Let's try manhattan distance for k between 1 and 9 : The Manhattan Distance between two points (X1, Y1) and (X2, Y2) is given by |X1 – X2| + |Y1 – Y2|."
      ],
      "metadata": {
        "id": "0IXra2Zt2QOb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for k in range(1,10):\n",
        "  pred =KNN_train(x_train_torch_23,y_train_torch_23,x_validation_torch_23,k,'Manhattan')\n",
        "  val_acc = torch.sum(pred == y_val_torch_23)\n",
        "  print(f\" k = {k} Validation accuracy on 2 and 3 digit \" , round(float(val_acc)/ pred.size()[0] *100,4),'%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HKDRZgAxbchJ",
        "outputId": "65244d9d-1fc3-4ef5-f61f-398283d2bd10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " k = 1 Validation accuracy on 2 and 3 digit  99.3914 %\n",
            " k = 2 Validation accuracy on 2 and 3 digit  99.2509 %\n",
            " k = 3 Validation accuracy on 2 and 3 digit  99.3914 %\n",
            " k = 4 Validation accuracy on 2 and 3 digit  99.3446 %\n",
            " k = 5 Validation accuracy on 2 and 3 digit  99.2509 %\n",
            " k = 6 Validation accuracy on 2 and 3 digit  99.2978 %\n",
            " k = 7 Validation accuracy on 2 and 3 digit  99.485 %\n",
            " k = 8 Validation accuracy on 2 and 3 digit  99.485 %\n",
            " k = 9 Validation accuracy on 2 and 3 digit  99.5318 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try the minkowsky distance with power equal to 3. \n",
        "The Minkowski distance between two variabes X and Y is defined as\n",
        "(∑i=1n|Xi−Yi|^p)^1/p"
      ],
      "metadata": {
        "id": "brFUUCZNfjx5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred =KNN_train(x_train_torch_23,y_train_torch_23,x_validation_torch_23,6,'Minkowsky')\n",
        "val_acc = torch.sum(pred == y_val_torch_23)\n",
        "print(f\"Validation accuracy on 2 and 3 digit \" , round(float(val_acc)/ pred.size()[0] *100,4),'%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mev5y_7bcjH",
        "outputId": "ec1eac4b-4399-4e64-ed87-260fc40aa6fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " k = 9 Validation accuracy on 2 and 3 digit  99.6723 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## d) Reporting results"
      ],
      "metadata": {
        "id": "MedRYyuQgjXJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By testing different methods for each hyperparameters. **The best accuracy for the test set is : 99.72 % by using k = 6 and the Euclidean distance**"
      ],
      "metadata": {
        "id": "cGbBd_562QRg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resume of what we have tried :"
      ],
      "metadata": {
        "id": "RX-O2Hv32QTn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Perform KNN with k = 5 and with euclidean distance. Test Accuracy = 99.53%\n",
        "2. Iterating over each k = 1 to k = 19 with euclidean distance in order to find the optimum k for the validation test. Optimum k = 12, Best test Accuracy = 99.57%\n",
        "3. **k = 6 best performance for test set. Test Accuracy = 99.72%**\n",
        "4. Iteratting over k=1 to k=10 with Manhattan distance. Results are very good but lower than k = 6 problem\n",
        "5. Minkowski power = 3 distance and k=6 . Test accuracy = 99.67%"
      ],
      "metadata": {
        "id": "c6kwUCRQgxyY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 3 : KNN multiclass"
      ],
      "metadata": {
        "id": "7S40bbVA2QWF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are gonna use the same code and perform it with all the labels values. Let's perfomr multi class KNN."
      ],
      "metadata": {
        "id": "zES7etP3GYaV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## a) Let's train our model, We have 98.01 accuracy with the train set"
      ],
      "metadata": {
        "id": "eCdzFygIHoMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred =KNN_train(X_train_tensor,y_train_torch,X_train_tensor,5)"
      ],
      "metadata": {
        "id": "ZAU0pqsP2TYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc = torch.sum(pred == y_train_torch)\n",
        "print(\"Train accuracy\" , round(float(train_acc)/ pred.size()[0] *100,4),'%')"
      ],
      "metadata": {
        "id": "48BlEpt0z_Z4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9950a2a5-25cc-437e-9361-d43484cf5349"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy 98.0184 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have 96.9% of accuracy for the validation set"
      ],
      "metadata": {
        "id": "JwjR1YWPH3HJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred =KNN_train(X_train_tensor,y_train_torch,X_validation_tensor,5,'Euclidean')"
      ],
      "metadata": {
        "id": "oSVZLPCdjYxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_acc = torch.sum(pred == y_validation_torch)\n",
        "print(\"Validation accuracy on multiclass KNN\" , round(float(val_acc)/ pred.size()[0] *100,4),'%')"
      ],
      "metadata": {
        "id": "khxtY50Amv9Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0e1ee48-633e-4c99-af51-1f79142742e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy on multiclass KNN 96.9429 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test accuracy on Multiclass KKN is 96.7%"
      ],
      "metadata": {
        "id": "TAF0QBIEH8r9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred =KNN_train(X_train_tensor,y_train_torch,X_test_tensor,5)"
      ],
      "metadata": {
        "id": "yMbvhZmvnG0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc = torch.sum(pred == y_test_torch)\n",
        "print(\"Test accuracy on multiclass KNN\" , round(float(test_acc)/ pred.size()[0] *100,2),'%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxXxc-IFnurw",
        "outputId": "2f5e52f0-e81b-462f-a13a-e02708da677b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy on multiclass KNN tensor(96.6762) %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BA5OsPQv5Inj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## b) Hyperparameters that we can tune are stil the same, we can tune the value of k and distance calculation formula"
      ],
      "metadata": {
        "id": "I5LyDK3JpzhH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "in other term we can thune our model to get the best k by testing mutliple k values. And we can test different type of distance computation. We can test the manhattan distance or even the jackard distance."
      ],
      "metadata": {
        "id": "aS1v3nNjpzTl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## c) Let's tune k parameter and test different distance computation"
      ],
      "metadata": {
        "id": "BYz7ODR2JLQ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What we can learn is that the accuracy of the model is decreasing slowly starting to k = 5. The optimum k for the validation set is k = 4 with an accuracy of 97.1%"
      ],
      "metadata": {
        "id": "twyIuFyHJpA-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for k in range(1,21):\n",
        "  pred =KNN_train(X_train_tensor,y_train_torch,X_validation_tensor,k,'Euclidean')\n",
        "  val_acc = torch.sum(pred == y_validation_torch)\n",
        "  print(f\"k = {k} Validation accuracy \" , round(float(val_acc)/ pred.size()[0] *100,4),'%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NChjRXDhIfAp",
        "outputId": "95805e9a-f585-43e2-b233-9d0d47525032"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k = 1 Validation accuracy  96.9143 %\n",
            "k = 2 Validation accuracy  96.4476 %\n",
            "k = 3 Validation accuracy  97.0571 %\n",
            "k = 4 Validation accuracy  97.0762 %\n",
            "k = 5 Validation accuracy  96.9429 %\n",
            "k = 6 Validation accuracy  96.9143 %\n",
            "k = 7 Validation accuracy  96.8857 %\n",
            "k = 8 Validation accuracy  96.8762 %\n",
            "k = 9 Validation accuracy  96.8571 %\n",
            "k = 10 Validation accuracy  96.7714 %\n",
            "k = 11 Validation accuracy  96.7238 %\n",
            "k = 12 Validation accuracy  96.6 %\n",
            "k = 13 Validation accuracy  96.5714 %\n",
            "k = 14 Validation accuracy  96.381 %\n",
            "k = 15 Validation accuracy  96.3714 %\n",
            "k = 16 Validation accuracy  96.419 %\n",
            "k = 17 Validation accuracy  96.3619 %\n",
            "k = 18 Validation accuracy  96.2476 %\n",
            "k = 19 Validation accuracy  96.2857 %\n",
            "k = 20 Validation accuracy  96.2 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's apply this optimum k to the test set and see if the accuracy is better. The performance is not that better."
      ],
      "metadata": {
        "id": "FRg-EdJRKDPq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred =KNN_train(X_train_tensor,y_train_torch,X_test_tensor,4)\n",
        "test_acc = torch.sum(pred == y_test_torch)\n",
        "print(\"Test accuracy on multiclass KNN\" , round(float(test_acc)/ pred.size()[0] *100,2),'%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqBfXsETIfGZ",
        "outputId": "5fea71df-a90f-49bd-f629-a9c8fb6e54af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy on multiclass KNN 96.57 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try an other distance calculation. The performance is not better then previous one. "
      ],
      "metadata": {
        "id": "8X175pqGpzSS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred =KNN_train(X_train_tensor,y_train_torch,X_validation_tensor,5,'Manhattan')\n",
        "val_acc = torch.sum(pred == y_validation_torch)\n",
        "print(\"Validation accuracy on multiclass KNN\" , round(float(val_acc)/ pred.size()[0] *100,4),'%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVU8lhtYIfhR",
        "outputId": "51797161-4cf0-42d7-b768-02014d66ede7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy on multiclass KNN 96.3714 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 4: Binary Classification via soft-margin SVM\n"
      ],
      "metadata": {
        "id": "jIPC9Ay1pzMt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First of all before starting coding. We have to replace labels values of digit 2 and 3 by 1 and -1 in order to perform our classification using Soft-margin SVM"
      ],
      "metadata": {
        "id": "zkBqDZ1tLMRg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_torch_svm= torch.where(y_train_torch_23==2,1,-1)\n",
        "y_test_torch_svm= torch.where(y_test_torch_23==2,1,-1)\n",
        "y_val_torch_svm= torch.where(y_val_torch_23==2,1,-1)"
      ],
      "metadata": {
        "id": "wvjA9JTRnM1o"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The goal of this part is to prepare the mini batch gradient descent using mini batch. We will shuffle the training set"
      ],
      "metadata": {
        "id": "d9y8QYqRLaCi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data.dataset import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_data = TensorDataset(x_train_torch_23,y_train_torch_svm)  \n",
        "test_data = TensorDataset(x_test_torch_23,y_test_torch_svm) \n",
        "val_data = TensorDataset(x_validation_torch_23,y_val_torch_svm) \n",
        "\n",
        "train_dataloader = DataLoader(train_data,batch_size = 64,shuffle = True )\n",
        "test_dataloader = DataLoader(test_data,batch_size = 64, shuffle = False)\n",
        "val_dataloader = DataLoader(val_data,batch_size = 64, shuffle = False)"
      ],
      "metadata": {
        "id": "qFy8RZXYp1rM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## a) SVM Classifier"
      ],
      "metadata": {
        "id": "k1_7m-EaLsox"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is our SVM classifier. We are using a linear model with a bias value wx+b "
      ],
      "metadata": {
        "id": "r9jLkUVoLwxc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SVM(torch.nn.Module):\n",
        "  def __init__(self,nb_of_features):\n",
        "    \n",
        "    super(SVM,self).__init__()\n",
        "    # We initialize our layer that will helps to create the decision boundary\n",
        "    self.linear = torch.nn.Linear(nb_of_features, 1, bias=True) \n",
        "\n",
        "  def forward(self,x):\n",
        "    y = self.linear(x)\n",
        "    return y.squeeze()\n",
        "\n",
        "\n",
        "# Initialization of our model\n",
        "model1 = SVM(x_train_torch_23.shape[1])\n"
      ],
      "metadata": {
        "id": "0rz1thfw4alZ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to calculate the accuracy of the model"
      ],
      "metadata": {
        "id": "kTckB1NdFq_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(y_pred,y):\n",
        "   return round(float(torch.sum(y_pred == y )/y.size()[0])*100,2)"
      ],
      "metadata": {
        "id": "uU1gCKDiFqJx"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## b) Train for 10 epochs with batch size 64 (1 epoch is equal to one entire passing of the\n",
        "train set; i.e., the entire train set is used for training once)."
      ],
      "metadata": {
        "id": "WRKez8pdEm-r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we initialize hyperparameters of our model"
      ],
      "metadata": {
        "id": "Uggva2G-Mkep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Set the model in train mode\n",
        "model1.train()\n",
        "C=1  # Not usefull now but we will use this condition later in this notebook\n",
        "learning_rate = 0.001 # We set the learning rate \n",
        "epochs = 10          \n",
        "total_loss = 0        #Loss of our algorithm\n",
        "nb_of_batch = 0       #Count the number of batch\n",
        "device = torch.device('cuda:0')"
      ],
      "metadata": {
        "id": "G8S6JclSLtYU"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we train our model in order to have the best values for the weights of our model. Reminder : We try to maximize the distance between the neareast point of each and the margin. And we try to minimize the weights values."
      ],
      "metadata": {
        "id": "7YXBeC8sMscu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#We initialize empty tensor for the outputs \n",
        "\n",
        "for epoch in range(epochs):\n",
        "  output = torch.empty(0)                 \n",
        "  y_train_values = torch.empty(0)\n",
        "  for batch in train_dataloader: # We apply the mini batch here \n",
        "    x_train,y_train = batch      # Instanciate x and y regarding the batch (64)\n",
        "    y_pred = model1.forward(x_train.float())    \n",
        "    # Our loss function that use the hinge loss and the norm of the weights \n",
        "    loss = (0.5 * torch.norm(model1.linear.weight.squeeze())**2 )+ (C* torch.clamp(1-y_pred*y_train,min=0)).mean()\n",
        "    loss.backward()\n",
        "    total_loss += float(loss)  # We add the loss of this batch to the total loss\n",
        "    nb_of_batch += 1\n",
        "    \n",
        "\n",
        "    # Just to retrieve values of y_train because the dataset is shuffleld and predictions\n",
        "    y_train_values = torch.cat((y_train_values,y_train),0)\n",
        "    output = torch.cat((output,y_pred),0)\n",
        "\n",
        "    with torch.no_grad():  # Here we apply de gradient descned regarding the learning rate and the weights\n",
        "      for param in model1.parameters():\n",
        "        param -= learning_rate*param.grad\n",
        "    model1.zero_grad()\n",
        "  final_pred = torch.where(output >=0, 2, 3 )\n",
        "  y_true = torch.where(y_train_values>= 0,2,3)\n",
        "  print('Epochs : '+ str(epoch) + ' Loss = '+ str(round((total_loss/nb_of_batch),4)) + ' Accuracy = ' + str(accuracy(y_true,final_pred)))\n",
        "\n",
        "# Final prediction we make the decision if we consider predictions are classe 2 or 3 if their higher than 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pq0Z0ZIfQF4B",
        "outputId": "f0056413-f8d0-4bdc-8423-ca223412652c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs : 0 Loss = 0.8333 Accuracy = 79.31\n",
            "Epochs : 1 Loss = 0.6664 Accuracy = 92.98\n",
            "Epochs : 2 Loss = 0.5865 Accuracy = 94.18\n",
            "Epochs : 3 Loss = 0.5388 Accuracy = 94.51\n",
            "Epochs : 4 Loss = 0.5065 Accuracy = 94.97\n",
            "Epochs : 5 Loss = 0.4828 Accuracy = 95.14\n",
            "Epochs : 6 Loss = 0.4647 Accuracy = 95.3\n",
            "Epochs : 7 Loss = 0.4503 Accuracy = 95.39\n",
            "Epochs : 8 Loss = 0.4386 Accuracy = 95.5\n",
            "Epochs : 9 Loss = 0.4289 Accuracy = 95.47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that our loss function decrease over epochs and the accuracy increases"
      ],
      "metadata": {
        "id": "IPVT1TyTBUhv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The accuracy for our Train set is 95.5% "
      ],
      "metadata": {
        "id": "AWacAW58Bc8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Train accuracy',accuracy(y_true,final_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0Ex24eXxbh4",
        "outputId": "a11b97e0-3b3b-4668-e403-277f6032e49d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy 95.49\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try on on the validation set. We found a better accuracy ! Our model genelralize well this situation"
      ],
      "metadata": {
        "id": "cAvPmDZ6Bi8O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## c) How should we choose the number of iterations to achieve good generalization? Train\n",
        "until you think the model has achieved good generalization"
      ],
      "metadata": {
        "id": "gObCBj31GNkg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we seen in the previous example we should choose the number of iterations we the loss starts to be stable. If we do too many epochs we might be overtting the model"
      ],
      "metadata": {
        "id": "4NNz41jxGQkY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try to see when the loss is stable for our model"
      ],
      "metadata": {
        "id": "uRDKe7VHGoO6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Set the model in train mode\n",
        "model2 = SVM(x_train_torch_23.shape[1])\n",
        "\n",
        "model2.train()\n",
        "C=1  # Not usefull now but we will use this condition later in this notebook\n",
        "learning_rate = 0.001 # We set the learning rate \n",
        "epochs = 40          \n",
        "total_loss = 0        #Loss of our algorithm\n",
        "nb_of_batch = 0       #Count the number of batch\n",
        "device = torch.device('cuda:0')\n",
        "\n",
        "#We initialize empty tensor for the outputs \n",
        "\n",
        "for epoch in range(epochs):\n",
        "  output = torch.empty(0)                 \n",
        "  y_train_values = torch.empty(0)\n",
        "  for batch in train_dataloader: # We apply the mini batch here \n",
        "    x_train,y_train = batch      # Instanciate x and y regarding the batch (64)\n",
        "    y_pred = model2.forward(x_train.float())    \n",
        "    # Our loss function that use the hinge loss and the norm of the weights \n",
        "    loss = (0.5 * torch.norm(model2.linear.weight.squeeze())**2 )+ (C* torch.clamp(1-y_pred*y_train,min=0)).mean()\n",
        "    loss.backward()\n",
        "    total_loss += float(loss)  # We add the loss of this batch to the total loss\n",
        "    nb_of_batch += 1\n",
        "    \n",
        "\n",
        "    # Just to retrieve values of y_train because the dataset is shuffleld and predictions\n",
        "    y_train_values = torch.cat((y_train_values,y_train),0)\n",
        "    output = torch.cat((output,y_pred),0)\n",
        "\n",
        "    with torch.no_grad():  # Here we apply de gradient descned regarding the learning rate and the weights\n",
        "      for param in model2.parameters():\n",
        "        param -= learning_rate*param.grad\n",
        "    model2.zero_grad()\n",
        "  final_pred = torch.where(output >=0, 2, 3 )\n",
        "  y_true = torch.where(y_train_values>= 0,2,3)\n",
        "  print('Epochs : '+ str(epoch) + ' Loss = '+ str(round((total_loss/nb_of_batch),4)) + ' Accuracy = ' + str(accuracy(y_true,final_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fdh5KECAGnoB",
        "outputId": "7f440277-ec78-4e75-e7b1-8399842b13d4"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs : 0 Loss = 0.8209 Accuracy = 85.94\n",
            "Epochs : 1 Loss = 0.6574 Accuracy = 93.84\n",
            "Epochs : 2 Loss = 0.5801 Accuracy = 94.54\n",
            "Epochs : 3 Loss = 0.534 Accuracy = 94.94\n",
            "Epochs : 4 Loss = 0.5027 Accuracy = 95.14\n",
            "Epochs : 5 Loss = 0.4797 Accuracy = 95.28\n",
            "Epochs : 6 Loss = 0.4621 Accuracy = 95.41\n",
            "Epochs : 7 Loss = 0.4481 Accuracy = 95.45\n",
            "Epochs : 8 Loss = 0.4367 Accuracy = 95.39\n",
            "Epochs : 9 Loss = 0.4272 Accuracy = 95.62\n",
            "Epochs : 10 Loss = 0.4193 Accuracy = 95.56\n",
            "Epochs : 11 Loss = 0.4125 Accuracy = 95.63\n",
            "Epochs : 12 Loss = 0.4067 Accuracy = 95.67\n",
            "Epochs : 13 Loss = 0.4017 Accuracy = 95.69\n",
            "Epochs : 14 Loss = 0.3972 Accuracy = 95.63\n",
            "Epochs : 15 Loss = 0.3933 Accuracy = 95.68\n",
            "Epochs : 16 Loss = 0.3899 Accuracy = 95.69\n",
            "Epochs : 17 Loss = 0.3868 Accuracy = 95.75\n",
            "Epochs : 18 Loss = 0.384 Accuracy = 95.66\n",
            "Epochs : 19 Loss = 0.3815 Accuracy = 95.66\n",
            "Epochs : 20 Loss = 0.3792 Accuracy = 95.68\n",
            "Epochs : 21 Loss = 0.3771 Accuracy = 95.75\n",
            "Epochs : 22 Loss = 0.3753 Accuracy = 95.72\n",
            "Epochs : 23 Loss = 0.3735 Accuracy = 95.7\n",
            "Epochs : 24 Loss = 0.3719 Accuracy = 95.74\n",
            "Epochs : 25 Loss = 0.3704 Accuracy = 95.75\n",
            "Epochs : 26 Loss = 0.3691 Accuracy = 95.77\n",
            "Epochs : 27 Loss = 0.3678 Accuracy = 95.78\n",
            "Epochs : 28 Loss = 0.3666 Accuracy = 95.75\n",
            "Epochs : 29 Loss = 0.3655 Accuracy = 95.74\n",
            "Epochs : 30 Loss = 0.3645 Accuracy = 95.7\n",
            "Epochs : 31 Loss = 0.3635 Accuracy = 95.75\n",
            "Epochs : 32 Loss = 0.3626 Accuracy = 95.76\n",
            "Epochs : 33 Loss = 0.3617 Accuracy = 95.72\n",
            "Epochs : 34 Loss = 0.3609 Accuracy = 95.75\n",
            "Epochs : 35 Loss = 0.3602 Accuracy = 95.76\n",
            "Epochs : 36 Loss = 0.3594 Accuracy = 95.77\n",
            "Epochs : 37 Loss = 0.3587 Accuracy = 95.74\n",
            "Epochs : 38 Loss = 0.3581 Accuracy = 95.76\n",
            "Epochs : 39 Loss = 0.3575 Accuracy = 95.73\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that regarding the results we see that the model start to be \"stable\" starting the 10th epoch."
      ],
      "metadata": {
        "id": "J09yUkSgHaEj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's perform the first model on the validation and tests set"
      ],
      "metadata": {
        "id": "uBtynI0TIqw3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nb_of_batch = 0\n",
        "loss = 0 \n",
        "total_loss=0\n",
        "model1.eval() # Model in evaluation mode\n",
        "output = torch.empty(0)\n",
        "for batch in test_dataloader: \n",
        "    x_test,y_test = batch\n",
        "    y_pred = model1.forward(x_test)\n",
        "    loss += (0.5 * torch.norm(model1.linear.weight.squeeze())**2 )+ (C* torch.clamp(1-y_pred*y_test,min=0)).mean()\n",
        "    total_loss += float(loss)\n",
        "    nb_of_batch += 1\n",
        "    output = torch.cat((output,y_pred),0)\n",
        "final_pred = torch.where(output >=0, 2, 3 )\n",
        "\n",
        "print(\"Loss : \" + str(total_loss/nb_of_batch) + \" Accuracy = \" + str(float(accuracy(final_pred,y_test_torch_23))))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUwrG3UKZzRS",
        "outputId": "0f5e07c4-b171-4246-bbda-0eb2d7498554"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss : 6.030509240487042 Accuracy = 96.64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On the test set the accuracy is up to 96.6% Actually the loss can be even lower. But the accuracy is pretty good"
      ],
      "metadata": {
        "id": "wr5M9s3DBv5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nb_of_batch = 0\n",
        "loss = 0 \n",
        "total_loss=0\n",
        "model1.eval()\n",
        "output = torch.empty(0)\n",
        "\n",
        "for batch in val_dataloader: \n",
        "    x_val,y_val = batch\n",
        "    y_pred = model1.forward(x_val)\n",
        "    loss += (0.5 * torch.norm(model1.linear.weight.squeeze())**2 )+ (C* torch.clamp(1-y_pred*y_val,min=0)).mean()\n",
        "    total_loss += float(loss)\n",
        "    nb_of_batch += 1\n",
        "    output = torch.cat((output,y_pred),0)\n",
        "final_pred = torch.where(output >=0, 2, 3 )\n",
        "\n",
        "print(\"Loss : \" + str(total_loss/nb_of_batch) + \" Accuracy = \" + str(float(accuracy(final_pred,y_val_torch_23))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaahDtk_djO4",
        "outputId": "005811d9-7bfa-438d-bb88-f72c1ed67f3c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss : 5.73075587609235 Accuracy = 96.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  d) What are the hyperparameters you can tune? \n"
      ],
      "metadata": {
        "id": "z6qlJj2tI73d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can tune the learning rate, the value of C, the number of epochs, the value of gamma in the loss function.\n",
        "\n",
        "C parameter adds a penalty for each misclassified data point. If c is small, the penalty for misclassified points is low so a decision boundary with a large margin is chosen at the expense of a greater number of misclassifications\n",
        "\n",
        "For high values of gamma, the points need to be very close to each other in order to be considered in the same class. Therefore, models with very large gamma values tend to overfit.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7hZV2VbwI9zg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##e) Try at least two other options for each hyperparameter. Report the performance for\n",
        "each optio\n",
        "**Let's try this rule :**\n",
        "\n",
        "**0.0001 < gamma < 10**\n",
        "\n",
        "**0.1 < c < 100**\n",
        "\n",
        "We are gonna try every value"
      ],
      "metadata": {
        "id": "8GkDsxvwQe6i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Set the model in train mode\n",
        "model2 = SVM(x_train_torch_23.shape[1])\n",
        "\n",
        "model2.train()\n",
        "C=[0.1,1,10,100]  # Not usefull now but we will use this condition later in this notebook\n",
        "learning_rate = 0.001 # We set the learning rate \n",
        "epochs = 10\n",
        "gamma = [0.001,0.01,0.1,1,10,10]          \n",
        "total_loss = 0        #Loss of our algorithm\n",
        "nb_of_batch = 0       #Count the number of batch\n",
        "device = torch.device('cuda:0')\n",
        "\n",
        "#We initialize empty tensor for the outputs \n",
        "for C_val in C:\n",
        "  for gamma_val in gamma:\n",
        "    for epoch in range(epochs):\n",
        "      output = torch.empty(0)                 \n",
        "      y_train_values = torch.empty(0)\n",
        "      for batch in train_dataloader: # We apply the mini batch here \n",
        "        x_train,y_train = batch      # Instanciate x and y regarding the batch (64)\n",
        "        y_pred = model2.forward(x_train.float())    \n",
        "        # Our loss function that use the hinge loss and the norm of the weights \n",
        "        loss = ((0.5/gamma_val) * torch.norm(model2.linear.weight.squeeze())**2 )+ (C_val* torch.clamp(1-y_pred*y_train,min=0)).mean()\n",
        "        loss.backward()\n",
        "        total_loss += float(loss)  # We add the loss of this batch to the total loss\n",
        "        nb_of_batch += 1\n",
        "        \n",
        "\n",
        "        # Just to retrieve values of y_train because the dataset is shuffleld and predictions\n",
        "        y_train_values = torch.cat((y_train_values,y_train),0)\n",
        "        output = torch.cat((output,y_pred),0)\n",
        "\n",
        "        with torch.no_grad():  # Here we apply de gradient descned regarding the learning rate and the weights\n",
        "          for param in model2.parameters():\n",
        "            param -= learning_rate*param.grad\n",
        "        model2.zero_grad()\n",
        "      final_pred = torch.where(output >=0, 2, 3 )\n",
        "      y_true = torch.where(y_train_values>= 0,2,3)\n",
        "      print('C : ' + str(C_val) + 'Gamma :' + str(gamma_val) + 'Epochs : '+ str(epoch) + ' Loss = '+ str(round((total_loss/nb_of_batch),4)) + ' Accuracy = '+ str(accuracy(y_true,final_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CcRZXkqI9M7",
        "outputId": "38e2ab9b-1ec7-4f58-a7b8-a54dafd6bc2a"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C : 0.1Gamma :0.001Epochs : 0 Loss = 1.21 Accuracy = 49.31\n",
            "C : 0.1Gamma :0.001Epochs : 1 Loss = 0.655 Accuracy = 49.4\n",
            "C : 0.1Gamma :0.001Epochs : 2 Loss = 0.47 Accuracy = 49.4\n",
            "C : 0.1Gamma :0.001Epochs : 3 Loss = 0.3775 Accuracy = 49.4\n",
            "C : 0.1Gamma :0.001Epochs : 4 Loss = 0.322 Accuracy = 49.4\n",
            "C : 0.1Gamma :0.001Epochs : 5 Loss = 0.285 Accuracy = 49.4\n",
            "C : 0.1Gamma :0.001Epochs : 6 Loss = 0.2586 Accuracy = 49.4\n",
            "C : 0.1Gamma :0.001Epochs : 7 Loss = 0.2388 Accuracy = 49.4\n",
            "C : 0.1Gamma :0.001Epochs : 8 Loss = 0.2234 Accuracy = 49.4\n",
            "C : 0.1Gamma :0.001Epochs : 9 Loss = 0.211 Accuracy = 49.4\n",
            "C : 0.1Gamma :0.01Epochs : 0 Loss = 0.2009 Accuracy = 49.4\n",
            "C : 0.1Gamma :0.01Epochs : 1 Loss = 0.1925 Accuracy = 49.4\n",
            "C : 0.1Gamma :0.01Epochs : 2 Loss = 0.1854 Accuracy = 49.4\n",
            "C : 0.1Gamma :0.01Epochs : 3 Loss = 0.1792 Accuracy = 49.4\n",
            "C : 0.1Gamma :0.01Epochs : 4 Loss = 0.1739 Accuracy = 49.4\n",
            "C : 0.1Gamma :0.01Epochs : 5 Loss = 0.1693 Accuracy = 49.4\n",
            "C : 0.1Gamma :0.01Epochs : 6 Loss = 0.1652 Accuracy = 49.4\n",
            "C : 0.1Gamma :0.01Epochs : 7 Loss = 0.1616 Accuracy = 49.4\n",
            "C : 0.1Gamma :0.01Epochs : 8 Loss = 0.1583 Accuracy = 49.4\n",
            "C : 0.1Gamma :0.01Epochs : 9 Loss = 0.1554 Accuracy = 49.4\n",
            "C : 0.1Gamma :0.1Epochs : 0 Loss = 0.1527 Accuracy = 75.01\n",
            "C : 0.1Gamma :0.1Epochs : 1 Loss = 0.1502 Accuracy = 90.25\n",
            "C : 0.1Gamma :0.1Epochs : 2 Loss = 0.1479 Accuracy = 90.98\n",
            "C : 0.1Gamma :0.1Epochs : 3 Loss = 0.1458 Accuracy = 90.53\n",
            "C : 0.1Gamma :0.1Epochs : 4 Loss = 0.1439 Accuracy = 90.96\n",
            "C : 0.1Gamma :0.1Epochs : 5 Loss = 0.1421 Accuracy = 91.29\n",
            "C : 0.1Gamma :0.1Epochs : 6 Loss = 0.1405 Accuracy = 91.11\n",
            "C : 0.1Gamma :0.1Epochs : 7 Loss = 0.1389 Accuracy = 91.2\n",
            "C : 0.1Gamma :0.1Epochs : 8 Loss = 0.1375 Accuracy = 90.94\n",
            "C : 0.1Gamma :0.1Epochs : 9 Loss = 0.1362 Accuracy = 91.26\n",
            "C : 0.1Gamma :1Epochs : 0 Loss = 0.1348 Accuracy = 92.37\n",
            "C : 0.1Gamma :1Epochs : 1 Loss = 0.1333 Accuracy = 92.94\n",
            "C : 0.1Gamma :1Epochs : 2 Loss = 0.1319 Accuracy = 92.71\n",
            "C : 0.1Gamma :1Epochs : 3 Loss = 0.1305 Accuracy = 92.73\n",
            "C : 0.1Gamma :1Epochs : 4 Loss = 0.1291 Accuracy = 92.67\n",
            "C : 0.1Gamma :1Epochs : 5 Loss = 0.1277 Accuracy = 92.63\n",
            "C : 0.1Gamma :1Epochs : 6 Loss = 0.1264 Accuracy = 92.46\n",
            "C : 0.1Gamma :1Epochs : 7 Loss = 0.1251 Accuracy = 92.53\n",
            "C : 0.1Gamma :1Epochs : 8 Loss = 0.1239 Accuracy = 92.45\n",
            "C : 0.1Gamma :1Epochs : 9 Loss = 0.1227 Accuracy = 92.48\n",
            "C : 0.1Gamma :10Epochs : 0 Loss = 0.1212 Accuracy = 92.46\n",
            "C : 0.1Gamma :10Epochs : 1 Loss = 0.1197 Accuracy = 92.39\n",
            "C : 0.1Gamma :10Epochs : 2 Loss = 0.118 Accuracy = 92.49\n",
            "C : 0.1Gamma :10Epochs : 3 Loss = 0.1164 Accuracy = 92.53\n",
            "C : 0.1Gamma :10Epochs : 4 Loss = 0.1148 Accuracy = 92.67\n",
            "C : 0.1Gamma :10Epochs : 5 Loss = 0.1133 Accuracy = 92.82\n",
            "C : 0.1Gamma :10Epochs : 6 Loss = 0.1117 Accuracy = 93.03\n",
            "C : 0.1Gamma :10Epochs : 7 Loss = 0.1102 Accuracy = 93.18\n",
            "C : 0.1Gamma :10Epochs : 8 Loss = 0.1088 Accuracy = 93.27\n",
            "C : 0.1Gamma :10Epochs : 9 Loss = 0.1074 Accuracy = 93.47\n",
            "C : 0.1Gamma :10Epochs : 0 Loss = 0.106 Accuracy = 93.6\n",
            "C : 0.1Gamma :10Epochs : 1 Loss = 0.1047 Accuracy = 93.78\n",
            "C : 0.1Gamma :10Epochs : 2 Loss = 0.1034 Accuracy = 93.87\n",
            "C : 0.1Gamma :10Epochs : 3 Loss = 0.1021 Accuracy = 93.94\n",
            "C : 0.1Gamma :10Epochs : 4 Loss = 0.1009 Accuracy = 93.98\n",
            "C : 0.1Gamma :10Epochs : 5 Loss = 0.0998 Accuracy = 94.05\n",
            "C : 0.1Gamma :10Epochs : 6 Loss = 0.0987 Accuracy = 94.14\n",
            "C : 0.1Gamma :10Epochs : 7 Loss = 0.0976 Accuracy = 94.23\n",
            "C : 0.1Gamma :10Epochs : 8 Loss = 0.0965 Accuracy = 94.3\n",
            "C : 0.1Gamma :10Epochs : 9 Loss = 0.0955 Accuracy = 94.36\n",
            "C : 1Gamma :0.001Epochs : 0 Loss = 0.1195 Accuracy = 49.91\n",
            "C : 1Gamma :0.001Epochs : 1 Loss = 0.1337 Accuracy = 50.29\n",
            "C : 1Gamma :0.001Epochs : 2 Loss = 0.1475 Accuracy = 50.43\n",
            "C : 1Gamma :0.001Epochs : 3 Loss = 0.1607 Accuracy = 51.51\n",
            "C : 1Gamma :0.001Epochs : 4 Loss = 0.1736 Accuracy = 52.84\n",
            "C : 1Gamma :0.001Epochs : 5 Loss = 0.1861 Accuracy = 54.04\n",
            "C : 1Gamma :0.001Epochs : 6 Loss = 0.1983 Accuracy = 57.47\n",
            "C : 1Gamma :0.001Epochs : 7 Loss = 0.21 Accuracy = 61.05\n",
            "C : 1Gamma :0.001Epochs : 8 Loss = 0.2215 Accuracy = 65.11\n",
            "C : 1Gamma :0.001Epochs : 9 Loss = 0.2326 Accuracy = 68.5\n",
            "C : 1Gamma :0.01Epochs : 0 Loss = 0.2431 Accuracy = 90.06\n",
            "C : 1Gamma :0.01Epochs : 1 Loss = 0.2532 Accuracy = 91.7\n",
            "C : 1Gamma :0.01Epochs : 2 Loss = 0.2632 Accuracy = 90.86\n",
            "C : 1Gamma :0.01Epochs : 3 Loss = 0.2728 Accuracy = 89.77\n",
            "C : 1Gamma :0.01Epochs : 4 Loss = 0.2822 Accuracy = 89.51\n",
            "C : 1Gamma :0.01Epochs : 5 Loss = 0.2913 Accuracy = 90.12\n",
            "C : 1Gamma :0.01Epochs : 6 Loss = 0.3002 Accuracy = 89.57\n",
            "C : 1Gamma :0.01Epochs : 7 Loss = 0.3089 Accuracy = 89.15\n",
            "C : 1Gamma :0.01Epochs : 8 Loss = 0.3174 Accuracy = 88.27\n",
            "C : 1Gamma :0.01Epochs : 9 Loss = 0.3256 Accuracy = 87.79\n",
            "C : 1Gamma :0.1Epochs : 0 Loss = 0.3318 Accuracy = 91.71\n",
            "C : 1Gamma :0.1Epochs : 1 Loss = 0.3371 Accuracy = 91.72\n",
            "C : 1Gamma :0.1Epochs : 2 Loss = 0.3423 Accuracy = 92.0\n",
            "C : 1Gamma :0.1Epochs : 3 Loss = 0.3473 Accuracy = 92.22\n",
            "C : 1Gamma :0.1Epochs : 4 Loss = 0.3522 Accuracy = 92.13\n",
            "C : 1Gamma :0.1Epochs : 5 Loss = 0.357 Accuracy = 92.3\n",
            "C : 1Gamma :0.1Epochs : 6 Loss = 0.3617 Accuracy = 92.22\n",
            "C : 1Gamma :0.1Epochs : 7 Loss = 0.3663 Accuracy = 92.15\n",
            "C : 1Gamma :0.1Epochs : 8 Loss = 0.3708 Accuracy = 92.23\n",
            "C : 1Gamma :0.1Epochs : 9 Loss = 0.3752 Accuracy = 91.87\n",
            "C : 1Gamma :1Epochs : 0 Loss = 0.3758 Accuracy = 92.99\n",
            "C : 1Gamma :1Epochs : 1 Loss = 0.3756 Accuracy = 94.03\n",
            "C : 1Gamma :1Epochs : 2 Loss = 0.3753 Accuracy = 94.54\n",
            "C : 1Gamma :1Epochs : 3 Loss = 0.3749 Accuracy = 94.98\n",
            "C : 1Gamma :1Epochs : 4 Loss = 0.3745 Accuracy = 95.14\n",
            "C : 1Gamma :1Epochs : 5 Loss = 0.3741 Accuracy = 95.32\n",
            "C : 1Gamma :1Epochs : 6 Loss = 0.3737 Accuracy = 95.38\n",
            "C : 1Gamma :1Epochs : 7 Loss = 0.3733 Accuracy = 95.42\n",
            "C : 1Gamma :1Epochs : 8 Loss = 0.3729 Accuracy = 95.53\n",
            "C : 1Gamma :1Epochs : 9 Loss = 0.3725 Accuracy = 95.55\n",
            "C : 1Gamma :10Epochs : 0 Loss = 0.3709 Accuracy = 95.59\n",
            "C : 1Gamma :10Epochs : 1 Loss = 0.3692 Accuracy = 95.74\n",
            "C : 1Gamma :10Epochs : 2 Loss = 0.3675 Accuracy = 95.78\n",
            "C : 1Gamma :10Epochs : 3 Loss = 0.3657 Accuracy = 95.8\n",
            "C : 1Gamma :10Epochs : 4 Loss = 0.3639 Accuracy = 95.91\n",
            "C : 1Gamma :10Epochs : 5 Loss = 0.3621 Accuracy = 96.03\n",
            "C : 1Gamma :10Epochs : 6 Loss = 0.3604 Accuracy = 96.05\n",
            "C : 1Gamma :10Epochs : 7 Loss = 0.3586 Accuracy = 96.13\n",
            "C : 1Gamma :10Epochs : 8 Loss = 0.3568 Accuracy = 96.15\n",
            "C : 1Gamma :10Epochs : 9 Loss = 0.3551 Accuracy = 96.18\n",
            "C : 1Gamma :10Epochs : 0 Loss = 0.3534 Accuracy = 96.3\n",
            "C : 1Gamma :10Epochs : 1 Loss = 0.3517 Accuracy = 96.23\n",
            "C : 1Gamma :10Epochs : 2 Loss = 0.35 Accuracy = 96.31\n",
            "C : 1Gamma :10Epochs : 3 Loss = 0.3483 Accuracy = 96.33\n",
            "C : 1Gamma :10Epochs : 4 Loss = 0.3467 Accuracy = 96.4\n",
            "C : 1Gamma :10Epochs : 5 Loss = 0.3451 Accuracy = 96.41\n",
            "C : 1Gamma :10Epochs : 6 Loss = 0.3435 Accuracy = 96.42\n",
            "C : 1Gamma :10Epochs : 7 Loss = 0.3419 Accuracy = 96.45\n",
            "C : 1Gamma :10Epochs : 8 Loss = 0.3404 Accuracy = 96.49\n",
            "C : 1Gamma :10Epochs : 9 Loss = 0.3389 Accuracy = 96.51\n",
            "C : 10Gamma :0.001Epochs : 0 Loss = 0.4357 Accuracy = 75.81\n",
            "C : 10Gamma :0.001Epochs : 1 Loss = 0.5127 Accuracy = 74.96\n",
            "C : 10Gamma :0.001Epochs : 2 Loss = 0.5884 Accuracy = 66.81\n",
            "C : 10Gamma :0.001Epochs : 3 Loss = 0.6629 Accuracy = 65.93\n",
            "C : 10Gamma :0.001Epochs : 4 Loss = 0.7363 Accuracy = 60.97\n",
            "C : 10Gamma :0.001Epochs : 5 Loss = 0.8084 Accuracy = 59.18\n",
            "C : 10Gamma :0.001Epochs : 6 Loss = 0.8794 Accuracy = 55.53\n",
            "C : 10Gamma :0.001Epochs : 7 Loss = 0.9492 Accuracy = 55.42\n",
            "C : 10Gamma :0.001Epochs : 8 Loss = 1.0179 Accuracy = 53.07\n",
            "C : 10Gamma :0.001Epochs : 9 Loss = 1.0856 Accuracy = 52.25\n",
            "C : 10Gamma :0.01Epochs : 0 Loss = 1.1366 Accuracy = 88.39\n",
            "C : 10Gamma :0.01Epochs : 1 Loss = 1.1862 Accuracy = 90.04\n",
            "C : 10Gamma :0.01Epochs : 2 Loss = 1.2352 Accuracy = 89.49\n",
            "C : 10Gamma :0.01Epochs : 3 Loss = 1.2833 Accuracy = 90.32\n",
            "C : 10Gamma :0.01Epochs : 4 Loss = 1.3308 Accuracy = 90.18\n",
            "C : 10Gamma :0.01Epochs : 5 Loss = 1.3776 Accuracy = 90.42\n",
            "C : 10Gamma :0.01Epochs : 6 Loss = 1.4238 Accuracy = 90.2\n",
            "C : 10Gamma :0.01Epochs : 7 Loss = 1.4691 Accuracy = 90.53\n",
            "C : 10Gamma :0.01Epochs : 8 Loss = 1.5139 Accuracy = 90.02\n",
            "C : 10Gamma :0.01Epochs : 9 Loss = 1.5581 Accuracy = 90.34\n",
            "C : 10Gamma :0.1Epochs : 0 Loss = 1.5719 Accuracy = 94.64\n",
            "C : 10Gamma :0.1Epochs : 1 Loss = 1.5846 Accuracy = 95.41\n",
            "C : 10Gamma :0.1Epochs : 2 Loss = 1.597 Accuracy = 95.71\n",
            "C : 10Gamma :0.1Epochs : 3 Loss = 1.6092 Accuracy = 95.65\n",
            "C : 10Gamma :0.1Epochs : 4 Loss = 1.6213 Accuracy = 95.69\n",
            "C : 10Gamma :0.1Epochs : 5 Loss = 1.6331 Accuracy = 95.64\n",
            "C : 10Gamma :0.1Epochs : 6 Loss = 1.6448 Accuracy = 95.69\n",
            "C : 10Gamma :0.1Epochs : 7 Loss = 1.6564 Accuracy = 95.72\n",
            "C : 10Gamma :0.1Epochs : 8 Loss = 1.6677 Accuracy = 95.8\n",
            "C : 10Gamma :0.1Epochs : 9 Loss = 1.679 Accuracy = 95.67\n",
            "C : 10Gamma :1Epochs : 0 Loss = 1.6799 Accuracy = 96.0\n",
            "C : 10Gamma :1Epochs : 1 Loss = 1.6794 Accuracy = 96.37\n",
            "C : 10Gamma :1Epochs : 2 Loss = 1.6787 Accuracy = 96.56\n",
            "C : 10Gamma :1Epochs : 3 Loss = 1.6779 Accuracy = 96.71\n",
            "C : 10Gamma :1Epochs : 4 Loss = 1.677 Accuracy = 96.73\n",
            "C : 10Gamma :1Epochs : 5 Loss = 1.6762 Accuracy = 96.75\n",
            "C : 10Gamma :1Epochs : 6 Loss = 1.6753 Accuracy = 96.83\n",
            "C : 10Gamma :1Epochs : 7 Loss = 1.6745 Accuracy = 96.82\n",
            "C : 10Gamma :1Epochs : 8 Loss = 1.6736 Accuracy = 96.85\n",
            "C : 10Gamma :1Epochs : 9 Loss = 1.6728 Accuracy = 96.87\n",
            "C : 10Gamma :10Epochs : 0 Loss = 1.6692 Accuracy = 96.81\n",
            "C : 10Gamma :10Epochs : 1 Loss = 1.6653 Accuracy = 96.88\n",
            "C : 10Gamma :10Epochs : 2 Loss = 1.6612 Accuracy = 97.01\n",
            "C : 10Gamma :10Epochs : 3 Loss = 1.6571 Accuracy = 97.02\n",
            "C : 10Gamma :10Epochs : 4 Loss = 1.6529 Accuracy = 97.02\n",
            "C : 10Gamma :10Epochs : 5 Loss = 1.6487 Accuracy = 97.15\n",
            "C : 10Gamma :10Epochs : 6 Loss = 1.6445 Accuracy = 97.15\n",
            "C : 10Gamma :10Epochs : 7 Loss = 1.6403 Accuracy = 97.18\n",
            "C : 10Gamma :10Epochs : 8 Loss = 1.6361 Accuracy = 97.18\n",
            "C : 10Gamma :10Epochs : 9 Loss = 1.6319 Accuracy = 97.21\n",
            "C : 10Gamma :10Epochs : 0 Loss = 1.6278 Accuracy = 97.23\n",
            "C : 10Gamma :10Epochs : 1 Loss = 1.6237 Accuracy = 97.22\n",
            "C : 10Gamma :10Epochs : 2 Loss = 1.6195 Accuracy = 97.23\n",
            "C : 10Gamma :10Epochs : 3 Loss = 1.6155 Accuracy = 97.22\n",
            "C : 10Gamma :10Epochs : 4 Loss = 1.6115 Accuracy = 97.24\n",
            "C : 10Gamma :10Epochs : 5 Loss = 1.6075 Accuracy = 97.27\n",
            "C : 10Gamma :10Epochs : 6 Loss = 1.6035 Accuracy = 97.24\n",
            "C : 10Gamma :10Epochs : 7 Loss = 1.5996 Accuracy = 97.26\n",
            "C : 10Gamma :10Epochs : 8 Loss = 1.5957 Accuracy = 97.3\n",
            "C : 10Gamma :10Epochs : 9 Loss = 1.5918 Accuracy = 97.22\n",
            "C : 100Gamma :0.001Epochs : 0 Loss = 2.7675 Accuracy = 51.43\n",
            "C : 100Gamma :0.001Epochs : 1 Loss = 3.9566 Accuracy = 49.79\n",
            "C : 100Gamma :0.001Epochs : 2 Loss = 5.1158 Accuracy = 50.24\n",
            "C : 100Gamma :0.001Epochs : 3 Loss = 6.2557 Accuracy = 50.14\n",
            "C : 100Gamma :0.001Epochs : 4 Loss = 7.375 Accuracy = 50.74\n",
            "C : 100Gamma :0.001Epochs : 5 Loss = 8.5019 Accuracy = 49.82\n",
            "C : 100Gamma :0.001Epochs : 6 Loss = 9.6126 Accuracy = 50.25\n",
            "C : 100Gamma :0.001Epochs : 7 Loss = 10.7354 Accuracy = 49.52\n",
            "C : 100Gamma :0.001Epochs : 8 Loss = 11.8193 Accuracy = 50.03\n",
            "C : 100Gamma :0.001Epochs : 9 Loss = 12.9232 Accuracy = 49.6\n",
            "C : 100Gamma :0.01Epochs : 0 Loss = 13.1359 Accuracy = 86.36\n",
            "C : 100Gamma :0.01Epochs : 1 Loss = 13.3292 Accuracy = 88.55\n",
            "C : 100Gamma :0.01Epochs : 2 Loss = 13.525 Accuracy = 87.58\n",
            "C : 100Gamma :0.01Epochs : 3 Loss = 13.7081 Accuracy = 88.5\n",
            "C : 100Gamma :0.01Epochs : 4 Loss = 13.898 Accuracy = 88.2\n",
            "C : 100Gamma :0.01Epochs : 5 Loss = 14.0865 Accuracy = 88.08\n",
            "C : 100Gamma :0.01Epochs : 6 Loss = 14.2835 Accuracy = 87.54\n",
            "C : 100Gamma :0.01Epochs : 7 Loss = 14.4632 Accuracy = 88.47\n",
            "C : 100Gamma :0.01Epochs : 8 Loss = 14.6526 Accuracy = 87.76\n",
            "C : 100Gamma :0.01Epochs : 9 Loss = 14.8306 Accuracy = 88.48\n",
            "C : 100Gamma :0.1Epochs : 0 Loss = 14.8424 Accuracy = 95.89\n",
            "C : 100Gamma :0.1Epochs : 1 Loss = 14.8508 Accuracy = 96.47\n",
            "C : 100Gamma :0.1Epochs : 2 Loss = 14.8578 Accuracy = 96.51\n",
            "C : 100Gamma :0.1Epochs : 3 Loss = 14.866 Accuracy = 96.45\n",
            "C : 100Gamma :0.1Epochs : 4 Loss = 14.8745 Accuracy = 96.59\n",
            "C : 100Gamma :0.1Epochs : 5 Loss = 14.882 Accuracy = 96.6\n",
            "C : 100Gamma :0.1Epochs : 6 Loss = 14.8898 Accuracy = 96.43\n",
            "C : 100Gamma :0.1Epochs : 7 Loss = 14.8976 Accuracy = 96.36\n",
            "C : 100Gamma :0.1Epochs : 8 Loss = 14.9045 Accuracy = 96.67\n",
            "C : 100Gamma :0.1Epochs : 9 Loss = 14.9115 Accuracy = 96.52\n",
            "C : 100Gamma :1Epochs : 0 Loss = 14.8891 Accuracy = 96.79\n",
            "C : 100Gamma :1Epochs : 1 Loss = 14.8642 Accuracy = 97.07\n",
            "C : 100Gamma :1Epochs : 2 Loss = 14.8384 Accuracy = 97.17\n",
            "C : 100Gamma :1Epochs : 3 Loss = 14.8124 Accuracy = 97.21\n",
            "C : 100Gamma :1Epochs : 4 Loss = 14.7871 Accuracy = 97.26\n",
            "C : 100Gamma :1Epochs : 5 Loss = 14.7621 Accuracy = 97.26\n",
            "C : 100Gamma :1Epochs : 6 Loss = 14.7376 Accuracy = 97.22\n",
            "C : 100Gamma :1Epochs : 7 Loss = 14.7126 Accuracy = 97.35\n",
            "C : 100Gamma :1Epochs : 8 Loss = 14.688 Accuracy = 97.19\n",
            "C : 100Gamma :1Epochs : 9 Loss = 14.6635 Accuracy = 97.37\n",
            "C : 100Gamma :10Epochs : 0 Loss = 14.6314 Accuracy = 97.33\n",
            "C : 100Gamma :10Epochs : 1 Loss = 14.5991 Accuracy = 97.36\n",
            "C : 100Gamma :10Epochs : 2 Loss = 14.5662 Accuracy = 97.41\n",
            "C : 100Gamma :10Epochs : 3 Loss = 14.5335 Accuracy = 97.49\n",
            "C : 100Gamma :10Epochs : 4 Loss = 14.5008 Accuracy = 97.47\n",
            "C : 100Gamma :10Epochs : 5 Loss = 14.4682 Accuracy = 97.6\n",
            "C : 100Gamma :10Epochs : 6 Loss = 14.4356 Accuracy = 97.63\n",
            "C : 100Gamma :10Epochs : 7 Loss = 14.4033 Accuracy = 97.61\n",
            "C : 100Gamma :10Epochs : 8 Loss = 14.371 Accuracy = 97.66\n",
            "C : 100Gamma :10Epochs : 9 Loss = 14.3389 Accuracy = 97.63\n",
            "C : 100Gamma :10Epochs : 0 Loss = 14.3069 Accuracy = 97.57\n",
            "C : 100Gamma :10Epochs : 1 Loss = 14.2751 Accuracy = 97.66\n",
            "C : 100Gamma :10Epochs : 2 Loss = 14.2434 Accuracy = 97.7\n",
            "C : 100Gamma :10Epochs : 3 Loss = 14.2118 Accuracy = 97.68\n",
            "C : 100Gamma :10Epochs : 4 Loss = 14.1802 Accuracy = 97.75\n",
            "C : 100Gamma :10Epochs : 5 Loss = 14.149 Accuracy = 97.79\n",
            "C : 100Gamma :10Epochs : 6 Loss = 14.1181 Accuracy = 97.8\n",
            "C : 100Gamma :10Epochs : 7 Loss = 14.0876 Accuracy = 97.69\n",
            "C : 100Gamma :10Epochs : 8 Loss = 14.0571 Accuracy = 97.81\n",
            "C : 100Gamma :10Epochs : 9 Loss = 14.0266 Accuracy = 97.69\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The beter result is the last iteration when we got an accuracy of 97.70 %  Let's try it with the validation set"
      ],
      "metadata": {
        "id": "NWBRyOHeOeis"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On the validation test we have an accuracy of 98.03 % the best on for the SVM until now. "
      ],
      "metadata": {
        "id": "qXjcBHm_PU6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nb_of_batch = 0\n",
        "loss = 0 \n",
        "total_loss=0\n",
        "gamma = 10\n",
        "C = 100\n",
        "model2.eval() # Model in evaluation mode\n",
        "output = torch.empty(0)\n",
        "for batch in test_dataloader: \n",
        "    x_test,y_test = batch\n",
        "    y_pred = model2.forward(x_test)\n",
        "    loss += ((0.5/gamma) * torch.norm(model2.linear.weight.squeeze())**2 )+ (C* torch.clamp(1-y_pred*y_test,min=0)).mean()\n",
        "    total_loss += float(loss)\n",
        "    nb_of_batch += 1\n",
        "    output = torch.cat((output,y_pred),0)\n",
        "final_pred = torch.where(output >=0, 2, 3 )\n",
        "\n",
        "print(\"Loss : \" + str(total_loss/nb_of_batch) + \" Accuracy = \" + str(float(accuracy(final_pred,y_test_torch_23))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTcZK9JsOm3g",
        "outputId": "a6f24c55-7c6c-4f15-9d3d-18673c8f6ad4"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss : 113.43609630360322 Accuracy = 98.04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's perform this model on the test set"
      ],
      "metadata": {
        "id": "qg2kk3OWPUhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nb_of_batch = 0\n",
        "loss = 0 \n",
        "total_loss=0\n",
        "C= 100\n",
        "gamma = 10\n",
        "model2.eval()\n",
        "output = torch.empty(0)\n",
        "\n",
        "for batch in val_dataloader: \n",
        "    x_val,y_val = batch\n",
        "    y_pred = model2.forward(x_val)\n",
        "    loss += ((0.5/gamma) * torch.norm(model2.linear.weight.squeeze())**2 )+ (C* torch.clamp(1-y_pred*y_val,min=0)).mean()\n",
        "    total_loss += float(loss)\n",
        "    nb_of_batch += 1\n",
        "    output = torch.cat((output,y_pred),0)\n",
        "final_pred = torch.where(output >=0, 2, 3 )\n",
        "\n",
        "print(\"Loss : \" + str(total_loss/nb_of_batch) + \" Accuracy = \" + str(float(accuracy(final_pred,y_val_torch_23))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xO5lc8T7Phzm",
        "outputId": "924f0039-7a37-48c2-9c44-cdd94922556f"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss : 126.39813106200275 Accuracy = 97.47\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I8aMjaGiSrNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## f) You can try more options if you want. What is the final test accuracy\n",
        "\n",
        "Let's try to find the better learning rate"
      ],
      "metadata": {
        "id": "016nJnxXSrkB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = SVM(x_train_torch_23.shape[1])\n",
        "\n",
        "model2.train()\n",
        "C=100  # Not usefull now but we will use this condition later in this notebook\n",
        "learning_rate = [0.0001,0.001,0.002,0.005,0.0075,0.01,0.1] # We set the learning rate \n",
        "epochs = 10\n",
        "gamma =10       \n",
        "total_loss = 0        #Loss of our algorithm\n",
        "nb_of_batch = 0       #Count the number of batch\n",
        "device = torch.device('cuda:0')\n",
        "for lr in learning_rate:\n",
        "  for epoch in range(epochs):\n",
        "      output = torch.empty(0)                 \n",
        "      y_train_values = torch.empty(0)\n",
        "      for batch in train_dataloader: # We apply the mini batch here \n",
        "        x_train,y_train = batch      # Instanciate x and y regarding the batch (64)\n",
        "        y_pred = model2.forward(x_train.float())    \n",
        "        # Our loss function that use the hinge loss and the norm of the weights \n",
        "        loss = ((0.5/gamma_val) * torch.norm(model2.linear.weight.squeeze())**2 )+ (C_val* torch.clamp(1-y_pred*y_train,min=0)).mean()\n",
        "        loss.backward()\n",
        "        total_loss += float(loss)  # We add the loss of this batch to the total loss\n",
        "        nb_of_batch += 1\n",
        "          \n",
        "\n",
        "        # Just to retrieve values of y_train because the dataset is shuffleld and predictions\n",
        "        y_train_values = torch.cat((y_train_values,y_train),0)\n",
        "        output = torch.cat((output,y_pred),0)\n",
        "\n",
        "        with torch.no_grad():  # Here we apply de gradient descned regarding the learning rate and the weights\n",
        "            for param in model2.parameters():\n",
        "              param -= lr*param.grad\n",
        "            model2.zero_grad()\n",
        "      final_pred = torch.where(output >=0, 2, 3 )\n",
        "      y_true = torch.where(y_train_values>= 0,2,3)\n",
        "      print('Learning rate : ' + str(lr) + 'Epochs : '+ str(epoch) + ' Loss = '+ str(round((total_loss/nb_of_batch),4)) + ' Accuracy = '+ str(accuracy(y_true,final_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oecmsFMgQGil",
        "outputId": "9173825a-c661-43b5-de1d-c5cb3d39aac9"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate : 0.0001Epochs : 0 Loss = 23.2929 Accuracy = 93.27\n",
            "Learning rate : 0.0001Epochs : 1 Loss = 17.9726 Accuracy = 96.21\n",
            "Learning rate : 0.0001Epochs : 2 Loss = 15.6559 Accuracy = 96.5\n",
            "Learning rate : 0.0001Epochs : 3 Loss = 14.2982 Accuracy = 96.73\n",
            "Learning rate : 0.0001Epochs : 4 Loss = 13.3877 Accuracy = 96.85\n",
            "Learning rate : 0.0001Epochs : 5 Loss = 12.7239 Accuracy = 96.9\n",
            "Learning rate : 0.0001Epochs : 6 Loss = 12.2103 Accuracy = 96.98\n",
            "Learning rate : 0.0001Epochs : 7 Loss = 11.8008 Accuracy = 97.0\n",
            "Learning rate : 0.0001Epochs : 8 Loss = 11.4634 Accuracy = 97.03\n",
            "Learning rate : 0.0001Epochs : 9 Loss = 11.1778 Accuracy = 97.11\n",
            "Learning rate : 0.001Epochs : 0 Loss = 10.9404 Accuracy = 96.93\n",
            "Learning rate : 0.001Epochs : 1 Loss = 10.7048 Accuracy = 97.18\n",
            "Learning rate : 0.001Epochs : 2 Loss = 10.48 Accuracy = 97.21\n",
            "Learning rate : 0.001Epochs : 3 Loss = 10.2721 Accuracy = 97.34\n",
            "Learning rate : 0.001Epochs : 4 Loss = 10.0875 Accuracy = 97.37\n",
            "Learning rate : 0.001Epochs : 5 Loss = 9.9269 Accuracy = 97.34\n",
            "Learning rate : 0.001Epochs : 6 Loss = 9.7777 Accuracy = 97.4\n",
            "Learning rate : 0.001Epochs : 7 Loss = 9.6364 Accuracy = 97.54\n",
            "Learning rate : 0.001Epochs : 8 Loss = 9.5044 Accuracy = 97.38\n",
            "Learning rate : 0.001Epochs : 9 Loss = 9.3889 Accuracy = 97.47\n",
            "Learning rate : 0.002Epochs : 0 Loss = 9.3002 Accuracy = 97.37\n",
            "Learning rate : 0.002Epochs : 1 Loss = 9.2154 Accuracy = 97.48\n",
            "Learning rate : 0.002Epochs : 2 Loss = 9.1356 Accuracy = 97.46\n",
            "Learning rate : 0.002Epochs : 3 Loss = 9.0644 Accuracy = 97.4\n",
            "Learning rate : 0.002Epochs : 4 Loss = 8.993 Accuracy = 97.51\n",
            "Learning rate : 0.002Epochs : 5 Loss = 8.9245 Accuracy = 97.67\n",
            "Learning rate : 0.002Epochs : 6 Loss = 8.8618 Accuracy = 97.53\n",
            "Learning rate : 0.002Epochs : 7 Loss = 8.8037 Accuracy = 97.49\n",
            "Learning rate : 0.002Epochs : 8 Loss = 8.7493 Accuracy = 97.61\n",
            "Learning rate : 0.002Epochs : 9 Loss = 8.6997 Accuracy = 97.66\n",
            "Learning rate : 0.005Epochs : 0 Loss = 8.7281 Accuracy = 96.85\n",
            "Learning rate : 0.005Epochs : 1 Loss = 8.7289 Accuracy = 97.17\n",
            "Learning rate : 0.005Epochs : 2 Loss = 8.7309 Accuracy = 97.25\n",
            "Learning rate : 0.005Epochs : 3 Loss = 8.7246 Accuracy = 97.22\n",
            "Learning rate : 0.005Epochs : 4 Loss = 8.7127 Accuracy = 97.42\n",
            "Learning rate : 0.005Epochs : 5 Loss = 8.7167 Accuracy = 97.17\n",
            "Learning rate : 0.005Epochs : 6 Loss = 8.7168 Accuracy = 97.22\n",
            "Learning rate : 0.005Epochs : 7 Loss = 8.723 Accuracy = 97.05\n",
            "Learning rate : 0.005Epochs : 8 Loss = 8.7247 Accuracy = 97.23\n",
            "Learning rate : 0.005Epochs : 9 Loss = 8.7197 Accuracy = 97.34\n",
            "Learning rate : 0.0075Epochs : 0 Loss = 8.7832 Accuracy = 96.64\n",
            "Learning rate : 0.0075Epochs : 1 Loss = 8.831 Accuracy = 96.84\n",
            "Learning rate : 0.0075Epochs : 2 Loss = 8.8881 Accuracy = 96.59\n",
            "Learning rate : 0.0075Epochs : 3 Loss = 8.9319 Accuracy = 96.82\n",
            "Learning rate : 0.0075Epochs : 4 Loss = 8.9735 Accuracy = 96.82\n",
            "Learning rate : 0.0075Epochs : 5 Loss = 9.0057 Accuracy = 96.91\n",
            "Learning rate : 0.0075Epochs : 6 Loss = 9.0405 Accuracy = 96.91\n",
            "Learning rate : 0.0075Epochs : 7 Loss = 9.0769 Accuracy = 96.8\n",
            "Learning rate : 0.0075Epochs : 8 Loss = 9.1015 Accuracy = 96.9\n",
            "Learning rate : 0.0075Epochs : 9 Loss = 9.1245 Accuracy = 96.91\n",
            "Learning rate : 0.01Epochs : 0 Loss = 9.3233 Accuracy = 95.71\n",
            "Learning rate : 0.01Epochs : 1 Loss = 9.3693 Accuracy = 96.76\n",
            "Learning rate : 0.01Epochs : 2 Loss = 9.4909 Accuracy = 96.14\n",
            "Learning rate : 0.01Epochs : 3 Loss = 9.544 Accuracy = 96.64\n",
            "Learning rate : 0.01Epochs : 4 Loss = 9.6055 Accuracy = 96.41\n",
            "Learning rate : 0.01Epochs : 5 Loss = 9.7066 Accuracy = 96.45\n",
            "Learning rate : 0.01Epochs : 6 Loss = 9.7571 Accuracy = 96.77\n",
            "Learning rate : 0.01Epochs : 7 Loss = 9.819 Accuracy = 96.6\n",
            "Learning rate : 0.01Epochs : 8 Loss = 9.9212 Accuracy = 96.05\n",
            "Learning rate : 0.01Epochs : 9 Loss = 9.9657 Accuracy = 96.8\n",
            "Learning rate : 0.1Epochs : 0 Loss = 14.9067 Accuracy = 92.4\n",
            "Learning rate : 0.1Epochs : 1 Loss = 18.2272 Accuracy = 93.56\n",
            "Learning rate : 0.1Epochs : 2 Loss = 21.7204 Accuracy = 93.43\n",
            "Learning rate : 0.1Epochs : 3 Loss = 25.7845 Accuracy = 93.25\n",
            "Learning rate : 0.1Epochs : 4 Loss = 29.1504 Accuracy = 93.29\n",
            "Learning rate : 0.1Epochs : 5 Loss = 31.882 Accuracy = 94.19\n",
            "Learning rate : 0.1Epochs : 6 Loss = 34.8775 Accuracy = 93.33\n",
            "Learning rate : 0.1Epochs : 7 Loss = 37.6098 Accuracy = 93.4\n",
            "Learning rate : 0.1Epochs : 8 Loss = 40.7512 Accuracy = 93.34\n",
            "Learning rate : 0.1Epochs : 9 Loss = 42.9878 Accuracy = 93.87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-iWZpnCUjJR",
        "outputId": "633b4636-1901-4efd-ac0a-197d4bb3bf9f"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss : 849.0836720186121 Accuracy = 97.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Learning rate equal to 0.002 is the optimum "
      ],
      "metadata": {
        "id": "IwafVFoVUQfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = SVM(x_train_torch_23.shape[1])\n",
        "\n",
        "model2.train()\n",
        "C=100\n",
        "gamma = 100  # Not usefull now but we will use this condition later in this notebook\n",
        "learning_rate = 0.001 # We set the learning rate \n",
        "epochs = 10\n",
        "total_loss = 0        #Loss of our algorithm\n",
        "nb_of_batch = 0       #Count the number of batch\n",
        "device = torch.device('cuda:0')\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  output = torch.empty(0)                 \n",
        "  y_train_values = torch.empty(0)\n",
        "  for batch in train_dataloader: # We apply the mini batch here \n",
        "    x_train,y_train = batch      # Instanciate x and y regarding the batch (64)\n",
        "    y_pred = model2.forward(x_train.float())    \n",
        "    # Our loss function that use the hinge loss and the norm of the weights \n",
        "    loss = ((0.5/gamma) * torch.norm(model2.linear.weight.squeeze())**2 )+ (C* torch.clamp(1-y_pred*y_train,min=0)).mean()\n",
        "    loss.backward()\n",
        "    total_loss += float(loss)  # We add the loss of this batch to the total loss\n",
        "    nb_of_batch += 1\n",
        "    \n",
        "\n",
        "    # Just to retrieve values of y_train because the dataset is shuffleld and predictions\n",
        "    y_train_values = torch.cat((y_train_values,y_train),0)\n",
        "    output = torch.cat((output,y_pred),0)\n",
        "\n",
        "    with torch.no_grad():  # Here we apply de gradient descned regarding the learning rate and the weights\n",
        "      for param in model2.parameters():\n",
        "        param -= learning_rate*param.grad\n",
        "    model2.zero_grad()\n",
        "  final_pred = torch.where(output >=0, 2, 3 )\n",
        "  y_true = torch.where(y_train_values>= 0,2,3)\n",
        "  print('Epochs : '+ str(epoch) + ' Loss = '+ str(round((total_loss/nb_of_batch),4)) + ' Accuracy = ' + str(accuracy(y_true,final_pred)))\n",
        "\n",
        "# Final prediction we make the decision if we consider predictions are classe 2 or 3 if their higher than 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fs780OGCUJf3",
        "outputId": "7364bfe8-92f6-4b03-93dc-81d039cd7739"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs : 0 Loss = 12.659 Accuracy = 95.59\n",
            "Epochs : 1 Loss = 10.6457 Accuracy = 96.83\n",
            "Epochs : 2 Loss = 9.7656 Accuracy = 97.06\n",
            "Epochs : 3 Loss = 9.2393 Accuracy = 97.17\n",
            "Epochs : 4 Loss = 8.87 Accuracy = 97.31\n",
            "Epochs : 5 Loss = 8.5967 Accuracy = 97.39\n",
            "Epochs : 6 Loss = 8.3963 Accuracy = 97.45\n",
            "Epochs : 7 Loss = 8.2243 Accuracy = 97.4\n",
            "Epochs : 8 Loss = 8.0869 Accuracy = 97.5\n",
            "Epochs : 9 Loss = 7.9576 Accuracy = 97.54\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o38D-wLjUqrZ",
        "outputId": "f9bcc139-417a-4410-c4c9-6b5850fb1cf7"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss : 123.09158504710479 Accuracy = 97.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nb_of_batch = 0\n",
        "loss = 0 \n",
        "total_loss=0\n",
        "C= 100\n",
        "gamma = 10\n",
        "model2.eval()\n",
        "output = torch.empty(0)\n",
        "\n",
        "for batch in val_dataloader: \n",
        "    x_val,y_val = batch\n",
        "    y_pred = model2.forward(x_val)\n",
        "    loss += ((0.5/gamma) * torch.norm(model2.linear.weight.squeeze())**2 )+ (C* torch.clamp(1-y_pred*y_val,min=0)).mean()\n",
        "    total_loss += float(loss)\n",
        "    nb_of_batch += 1\n",
        "    output = torch.cat((output,y_pred),0)\n",
        "final_pred = torch.where(output >=0, 2, 3 )\n",
        "\n",
        "print(\"Loss : \" + str(total_loss/nb_of_batch) + \" Accuracy = \" + str(float(accuracy(final_pred,y_val_torch_23))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCTty1NyVCFa",
        "outputId": "d33db43c-d294-4b74-86a7-db0aefb09e69"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss : 134.17425298690796 Accuracy = 97.61\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nb_of_batch = 0\n",
        "loss = 0 \n",
        "total_loss=0\n",
        "gamma = 10\n",
        "C = 100\n",
        "model2.eval() # Model in evaluation mode\n",
        "output = torch.empty(0)\n",
        "for batch in test_dataloader: \n",
        "    x_test,y_test = batch\n",
        "    y_pred = model2.forward(x_test)\n",
        "    loss += ((0.5/gamma) * torch.norm(model2.linear.weight.squeeze())**2 )+ (C* torch.clamp(1-y_pred*y_test,min=0)).mean()\n",
        "    total_loss += float(loss)\n",
        "    nb_of_batch += 1\n",
        "    output = torch.cat((output,y_pred),0)\n",
        "final_pred = torch.where(output >=0, 2, 3 )\n",
        "\n",
        "print(\"Loss : \" + str(total_loss/nb_of_batch) + \" Accuracy = \" + str(float(accuracy(final_pred,y_test_torch_23))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIUAr8EQYGaL",
        "outputId": "739e6348-9654-4def-c172-2665bc61499f"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss : 128.60798013911528 Accuracy = 97.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So after trying the best parameters for our model we found the accuracy of 98% for the test set"
      ],
      "metadata": {
        "id": "Lt8VIt5uVIO6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resume"
      ],
      "metadata": {
        "id": "aP4xUuO2Voih"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What we have done in this Binary SVM Classification using soft max margin\n",
        "\n",
        "- Created the SVM classifier\n",
        "- Trained the model with simple parameters and 10 epochs\n",
        "- evaluated the model on the validation set\n",
        "- performed the model on the test set\n",
        "- Tuned hyperparametrs C and Gamma \n",
        "- tested on validation and tests set\n",
        "- Tuned the learning rate \n",
        "- Tested on validation and tests set\n",
        "\n",
        "## Final accuracy of the test set is 98% with C = 100 gamma = 10 lr= 0.002 \n",
        "\n",
        "The value of C is very high and the loss will be high to because we penalize more with high value of C our model when it' getting wrong. The value of gamma is pretty because we tried to only consider points that are very close like a unique class"
      ],
      "metadata": {
        "id": "w_wwSrvDVrnk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mAd-zh9nVwww"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
